{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polygon Color Generation with Conditional UNet\n",
    "\n",
    "This notebook demonstrates inference and testing of the trained conditional UNet model that generates colored polygons based on input polygon images and color names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from unet_model import ConditionalUNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color mapping (same as used in training)\n",
    "COLOR_MAP = {\n",
    "    'red': 0,\n",
    "    'blue': 1,\n",
    "    'green': 2,\n",
    "    'yellow': 3,\n",
    "    'purple': 4,\n",
    "    'orange': 5,\n",
    "    'cyan': 6,\n",
    "    'magenta': 7\n",
    "}\n",
    "\n",
    "# Reverse mapping for display\n",
    "IDX_TO_COLOR = {v: k for k, v in COLOR_MAP.items()}\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "model = ConditionalUNet(\n",
    "    n_channels=1,\n",
    "    n_classes=3,\n",
    "    num_colors=len(COLOR_MAP),\n",
    "    embed_dim=64\n",
    ").to(device)\n",
    "\n",
    "# Load trained weights\n",
    "checkpoint = torch.load('best_polygon_unet.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess input polygon image\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return tensor\n",
    "\n",
    "def generate_colored_polygon(model, polygon_path, color_name, device):\n",
    "    \"\"\"Generate colored polygon using the trained model\"\"\"\n",
    "    # Preprocess input\n",
    "    input_tensor = preprocess_image(polygon_path).to(device)\n",
    "    \n",
    "    # Get color index\n",
    "    color_idx = torch.tensor([COLOR_MAP[color_name]], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Generate output\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor, color_idx)\n",
    "    \n",
    "    # Convert to PIL image\n",
    "    output_np = output.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "    output_np = np.clip(output_np, 0, 1)\n",
    "    output_image = Image.fromarray((output_np * 255).astype(np.uint8))\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "def visualize_results(polygon_path, color_name, generated_image, actual_image_path=None):\n",
    "    \"\"\"Visualize input, generated output, and actual output\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3 if actual_image_path else 2, figsize=(15, 5))\n",
    "    \n",
    "    # Input polygon\n",
    "    input_img = Image.open(polygon_path).convert('RGB')\n",
    "    axes[0].imshow(input_img)\n",
    "    axes[0].set_title(f\"Input: {os.path.basename(polygon_path)}\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Generated output\n",
    "    axes[1].imshow(generated_image)\n",
    "    axes[1].set_title(f\"Generated: {color_name} polygon\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    if actual_image_path:\n",
    "        actual_img = Image.open(actual_image_path)\n",
    "        axes[2].imshow(actual_img)\n",
    "        axes[2].set_title(f\"Actual: {color_name} polygon\")\n",
    "        axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test with Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation data\n",
    "with open('validation/data.json', 'r') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "print(f\"Testing with {len(val_data)} validation samples...\")\n",
    "\n",
    "# Test a few samples\n",
    "for i, item in enumerate(val_data[:3]):\n",
    "    polygon_path = f\"validation/inputs/{item['input_polygon']}\"\n",
    "    color_name = item['colour']\n",
    "    actual_path = f\"validation/outputs/{item['output_image']}\"\n",
    "    \n",
    "    print(f\"\\nTest {i+1}: {item['input_polygon']} -> {color_name}\")\n",
    "    \n",
    "    # Generate colored polygon\n",
    "    generated = generate_colored_polygon(model, polygon_path, color_name, device)\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_results(polygon_path, color_name, generated, actual_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing function\n",
    "def interactive_test(polygon_name, color_name):\n",
    "    \"\"\"Test with specific polygon and color\"\"\"\n",
    "    polygon_path = f\"training/inputs/{polygon_name}\"\n",
    "    \n",
    "    if not os.path.exists(polygon_path):\n",
    "        print(f\"Polygon {polygon_name} not found!\")\n",
    "        return\n",
    "    \n",
    "    if color_name not in COLOR_MAP:\n",
    "        print(f\"Color {color_name} not available. Available colors: {list(COLOR_MAP.keys())}\")\n",
    "        return\n",
    "    \n",
    "    # Generate colored polygon\n",
    "    generated = generate_colored_polygon(model, polygon_path, color_name, device)\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_results(polygon_path, color_name, generated)\n",
    "    \n",
    "    return generated\n",
    "\n",
    "# Test with different combinations\n",
    "print(\"Available polygons:\", [f for f in os.listdir('training/inputs') if f.endswith('.png')])\n",
    "print(\"Available colors:\", list(COLOR_MAP.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test specific combinations\n",
    "interactive_test('triangle.png', 'blue')\n",
    "interactive_test('square.png', 'green')\n",
    "interactive_test('circle.png', 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_metrics(generated, actual):\n",
    "    \"\"\"Calculate MSE and SSIM between generated and actual images\"\"\"\n",
    "    # Convert PIL images to tensors\n",
    "    transform = transforms.ToTensor()\n",
    "    gen_tensor = transform(generated).unsqueeze(0)\n",
    "    actual_tensor = transform(actual).unsqueeze(0)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = F.mse_loss(gen_tensor, actual_tensor).item()\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Evaluate on validation set\n",
    "mse_scores = []\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for item in val_data:\n",
    "    polygon_path = f\"validation/inputs/{item['input_polygon']}\"\n",
    "    color_name = item['colour']\n",
    "    actual_path = f\"validation/outputs/{item['output_image']}\"\n",
    "    \n",
    "    # Generate\n",
    "    generated = generate_colored_polygon(model, polygon_path, color_name, device)\n",
    "    actual = Image.open(actual_path)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = calculate_metrics(generated, actual)\n",
    "    mse_scores.append(mse)\n",
    "    \n",
    "    print(f\"{item['input_polygon']} -> {color_name}: MSE = {mse:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"Min MSE: {np.min(mse_scores):.4f}\")\n",
    "print(f\"Max MSE: {np.max(mse_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Generated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs('generated_samples', exist_ok=True)\n",
    "\n",
    "# Generate and save samples for all validation data\n",
    "for item in val_data:\n",
    "    polygon_path = f\"validation/inputs/{item['input_polygon']}\"\n",
    "    color_name = item['colour']\n",
    "    \n",
    "    # Generate\n",
    "    generated = generate_colored_polygon(model, polygon_path, color_name, device)\n",
    "    \n",
    "    # Save\n",
    "    filename = f\"generated_{item['output_image']}\"\n",
    "    generated.save(f\"generated_samples/{filename}\")\n",
    "    \n",
    "print(\"Generated samples saved to 'generated_samples/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model summary\n",
    "print(\"Model Architecture:\")\n",
    "print(\"-\" * 50)\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / (1024*1024):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}